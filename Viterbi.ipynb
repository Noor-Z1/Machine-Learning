{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noor-Z1/Machine-Learning/blob/main/Viterbi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class HMM:\n",
        "    def __init__(self, A, B, Pi):\n",
        "        self.A = A\n",
        "        self.B = B\n",
        "        self.Pi = Pi\n",
        "\n",
        "    def forward_log(self, O: list):\n",
        "        \"\"\"\n",
        "        :param O: is the sequence (an array of) discrete (integer) observations, i.e. [0 , 2 ,1 ,3 , 4]\n",
        "        :return: ln P(O|λ) score for the given observation, ln: natural logarithm\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        #instead of recursion, I follow the tabular dynamic programming approach\n",
        "\n",
        "        num_observ = len(O)\n",
        "        num_states = self.A.shape[0]\n",
        "\n",
        "        #initializing an alpha matrix of size based on observations and number of states, where alpha is the forward variable\n",
        "        alpha = np.zeros((num_observ, num_states))\n",
        "\n",
        "        # α1(i) = P(O1 = Ok, q1 = Si) = πibim\n",
        "        #initializing the 0th row of the matrix using the emission prob and initial state distribution and the given equation\n",
        "\n",
        "        #c=0\n",
        "        normalizer = np.zeros(num_observ)\n",
        "\n",
        "        for i in range(0,num_states):\n",
        "          alpha[0][i] = self.Pi[i] * self.B[i][O[0]]\n",
        "          normalizer[0]+=alpha[0][i]\n",
        "\n",
        "        #tabular/dp approach to calculate α t+1(i) (alpha value at next time step)\n",
        "        #Note that to calculate the inside of the summation part of the equation, the matrix A = aij needs to be dotted with the prev alpha value\n",
        "\n",
        "        for t in range(1, num_observ):\n",
        "            normalizer[t]=0\n",
        "            alpha[t, :] = alpha[t-1].dot(self.A)            #note that dotting avoids another loop\n",
        "            alpha[t, :] = alpha[t, :] * self.B[:, O[t]]     #this is multiplication with bjv part of the equation. corresponding rows in B are multiplied with the corresponding alpha values using this notation\n",
        "\n",
        "\n",
        "            for i in range(0,num_states):  #to find the normalizer\n",
        "              normalizer[t]+=alpha[t][i]\n",
        "\n",
        "            normalizer[t] = 1.0/normalizer[t]\n",
        "\n",
        "            for i in range(0,num_states):  #normalizing calculated alphas.\n",
        "              alpha[t][i]*= normalizer[t]\n",
        "\n",
        "\n",
        "        #the return is equivalent to returning c\n",
        "        #for t in range(1,num_observ):\n",
        "        # c+= np.log(normalizer[t])\n",
        "\n",
        "\n",
        "\n",
        "        return -1 * (np.sum(np.log(normalizer[1:])))\n",
        "\n",
        "\n",
        "    def viterbi_log(self, O: list):\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        :param O: is an array of discrete (integer) observations, i.e. [0, 2, 1 ,3, 4]\n",
        "        :return: the tuple (Q*, ln P(Q*|O,λ)), Q* is the most probable state sequence for the given O\n",
        "        \"\"\"\n",
        "\n",
        "        #initializing tables\n",
        "        num_observ = len(O)\n",
        "        num_states = self.A.shape[0]\n",
        "\n",
        "        Viterbi = np.zeros((num_observ, num_states)) #Viterbi table -> DELTA\n",
        "        psi = np.zeros((num_observ, num_states))  #best path table\n",
        "\n",
        "\n",
        "        #inititalization part of the 0th row using the first observation\n",
        "        for i in range(0, num_states):\n",
        "          Viterbi[0][i] = np.log(self.Pi[i]) + np.log(self.B[i][O[0]])    # equation 7 calculation -> need to iterate through the states to find   ln πi + ln bie\n",
        "\n",
        "\n",
        "\n",
        "        #forward pass to get most probable prev state\n",
        "        #again using iterative approach instead of recursive\n",
        "\n",
        "        for t in range(1, num_observ):\n",
        "            for j in range(num_states):\n",
        "                # t is same as t+1 from the assignment equation and t-1 is same as t from assignment eq\n",
        "\n",
        "                Viterbi[t][j]= np.max(Viterbi[t-1] + np.log(self.A[:, j])) + np.log(self.B[j][O[t]])  # equation 8 calc\n",
        "\n",
        "                psi[t][j] = np.argmax(Viterbi[t-1] + np.log(self.A[:, j])) #equation 9 calc\n",
        "\n",
        "\n",
        "        #most likely state for last time stamp, since its the last time step, I use Viterbi[-1]\n",
        "        q_star = np.argmax(Viterbi[-1])\n",
        "\n",
        "\n",
        "        #backward tracing to get Max Likelihood seq (as described in assignment)\n",
        "        QSTAR_seq=[]\n",
        "        QSTAR_seq.append(int(q_star))\n",
        "        #backward tracing to get Max Likelihood seq (as described in assignment)\n",
        "        t= num_observ -1\n",
        "\n",
        "\n",
        "        while(t>0):\n",
        "            QSTAR_seq.append(int(psi[t][int(QSTAR_seq[-1])]))  #need to convert the last element of qstar to int so it works as index\n",
        "            t = t-1\n",
        "\n",
        "\n",
        "        QSTAR_seq = QSTAR_seq[::-1]   #need to reverse the qstar list to get the correct order since in back tracking the last is entered first in the array\n",
        "\n",
        "\n",
        "\n",
        "        return (QSTAR_seq, np.max(Viterbi[-1]))\n"
      ],
      "metadata": {
        "id": "nam0aPsi3unF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from HMM import HMM\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "A = np.array([[0.4, 0.6],\n",
        "              [0.7, 0.3]], dtype=np.float128)\n",
        "\n",
        "B = np.array([[0.3, 0.4, 0.3],\n",
        "              [0.1, 0.2, 0.7]], dtype=np.float128)\n",
        "\n",
        "Pi = np.array([0.6, 0.4], dtype=np.float128)\n",
        "\n",
        "hmm = HMM(A, B, Pi)\n",
        "\n",
        "O1 = [2, 1, 0]\n",
        "O2 = [0,0,2,1,0]\n",
        "print(hmm.forward_log(O1))\n",
        "print(hmm.forward_log(O2))\n",
        "\n",
        "\n",
        "print(hmm.viterbi_log(O1))\n",
        "print(hmm.viterbi_log(O2))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7PpZEk-3ARG",
        "outputId": "117a6d75-423e-45d7-96db-f287a4a50f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3.5574302276937386\n",
            "-6.620857514019081\n",
            "([1, 0, 0], -4.666194887825866)\n",
            "([0, 0, 1, 0, 0], -8.09579174400972)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t5Qs21g0Peih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mfvSILCdb52m"
      }
    }
  ]
}