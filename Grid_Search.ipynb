{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noor-Z1/Machine-Learning/blob/main/Grid_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKPgFXeRL2pX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class DataLoader:\n",
        "    @staticmethod\n",
        "    def load_credit(file_path):\n",
        "        dataset = []\n",
        "        labels = []\n",
        "        file = open(file_path, \"r\")\n",
        "        for line in file:\n",
        "            line = line.strip(\"\\n\\r\")\n",
        "            # to get rid of extra lines that do not contain any information\n",
        "            if len(line) < 5:\n",
        "                continue\n",
        "            parts = line.split(\" \")\n",
        "            data = []\n",
        "            numeric_transformer = float\n",
        "            # Attribute 1: (qualitative) - Status of existing checking account\n",
        "            attr_1 = {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}\n",
        "            data.append(attr_1[parts[0]]) #\n",
        "            # Attribute 2: (numerical) - Duration in month\n",
        "            data.append(numeric_transformer(parts[1]))\n",
        "            # Attribute 3: (qualitative) Credit history\n",
        "            attr_3 = {'A30':0, 'A31':1, 'A32':2, 'A33':3, 'A34':4}\n",
        "            data.append(attr_3[parts[2]])\n",
        "            # Attribute 4: (qualitative) Purpose\n",
        "            attr_4 = {'A40': 0, 'A41': 1, 'A42': 2, 'A43': 3, 'A44': 4, 'A45': 5, 'A46': 6, 'A47': 7, 'A48': 8, 'A49': 9, 'A410': 10}\n",
        "            data.append(attr_4[parts[3]])\n",
        "            # Attribute 5: (numerical) # Credit amount\n",
        "            data.append(numeric_transformer(parts[4]))\n",
        "            # Attibute 6: (qualitative) Savings account / bonds\n",
        "            attr_6 = {'A61': 0, 'A62': 1,'A63': 2,'A64': 3,'A65': 4}\n",
        "            data.append(attr_6[parts[5]])\n",
        "            # Attribute 7: (qualitative) Present employment since\n",
        "            attr_7 = {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}\n",
        "            data.append(attr_7[parts[6]])\n",
        "            # Attribute 8: (numerical) Installment rate in percentage of disposable income\n",
        "            data.append(numeric_transformer(parts[7]))\n",
        "            # Attribute 9: (qualitative) Personal status and sex\n",
        "            attr_9 = {'A91': 0, 'A92': 1, 'A93': 2, 'A94': 3, 'A95': 4}\n",
        "            data.append(attr_9[parts[8]])\n",
        "            # Attribute 10: (qualitative) Other debtors / guarantors\n",
        "            attr_10 = {'A101': 0, 'A102': 1, 'A103': 2}\n",
        "            data.append(attr_10[parts[9]])\n",
        "            # Attribute 11: (numerical) Present residence since\n",
        "            data.append(numeric_transformer(parts[10]))\n",
        "            # Attribute 12: (qualitative) Property\n",
        "            attr_12 = {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}\n",
        "            data.append(attr_12[parts[11]])\n",
        "            # Attribute 13: (numerical) Age in years\n",
        "            data.append(numeric_transformer(parts[12]))\n",
        "            # Attribute 14: (qualitative) Other installment plans\n",
        "            attr_14 = {'A141': 0, 'A142': 1, 'A143': 2}\n",
        "            data.append(attr_14[parts[13]])\n",
        "            # Attribute 15: (qualitative) Housing\n",
        "            attr_15 = {'A151': 0, 'A152': 1, 'A153': 2}\n",
        "            data.append(attr_15[parts[14]])\n",
        "            # Attribute 16: (numerical) Number of existing credits at this bank\n",
        "            data.append(numeric_transformer(parts[15]))\n",
        "            # Attribute 17: (qualitative) Job\n",
        "            attr_17 = {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}\n",
        "            data.append(attr_17[parts[16]])\n",
        "            # Attribute 18: (numerical) Number of people being liable to provide maintenance for\n",
        "            data.append(numeric_transformer(parts[17]))\n",
        "            # Attribute 19: (qualitative) # Telephone\n",
        "            attr_19 = {'A191': 0, 'A192': 1}\n",
        "            data.append(attr_19[parts[18]])\n",
        "            # Attribute 20: (qualitative) foreign worker\n",
        "            attr_20 = {'A201': 0, 'A202': 1}\n",
        "            data.append(attr_20[parts[19]])\n",
        "            dataset.append(data)\n",
        "            # 1 good, 2 bad for credit application\n",
        "            labels.append(1 if parts[20] == \"1\" else 0)\n",
        "        file.close()\n",
        "        return np.array(dataset, dtype=np.float32), np.array(labels, dtype=np.int32)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_credit_with_onehot(file_path):\n",
        "        dataset = []\n",
        "        labels = []\n",
        "        file = open(file_path, \"r\")\n",
        "        for line in file:\n",
        "            line = line.strip(\"\\n\\r\")\n",
        "            # to get rid of extra lines that do not contain any information\n",
        "            if len(line) < 5:\n",
        "                continue\n",
        "            parts = line.split(\" \")\n",
        "            data = []\n",
        "            numeric_transformer = float\n",
        "            # Attribute 1: (qualitative) - Status of existing checking account\n",
        "            attr_1 = {'A11': [1,0,0,0], 'A12': [0,1,0,0], 'A13': [0,0,1,0], 'A14': [0,0,0,1]}\n",
        "            data.extend(attr_1[parts[0]])  #\n",
        "            # Attribute 2: (numerical) - Duration in month\n",
        "            data.append(numeric_transformer(parts[1]))\n",
        "            # Attribute 3: (qualitative) Credit history\n",
        "            attr_3 = {'A30': [1,0,0,0,0], 'A31': [0,1,0,0,0], 'A32': [0,0,1,0,0], 'A33': [0,0,0,1,0], 'A34': [0,0,0,0,1]}\n",
        "            data.extend(attr_3[parts[2]])\n",
        "            # Attribute 4: (qualitative) Purpose\n",
        "            attr_4 = {'A40': [1,0,0,0,0,0,0,0,0,0,0], 'A41': [0,1,0,0,0,0,0,0,0,0,0], 'A42': [0,0,1,0,0,0,0,0,0,0,0],\n",
        "                      'A43': [0,0,0,1,0,0,0,0,0,0,0], 'A44': [0,0,0,0,1,0,0,0,0,0,0], 'A45': [0,0,0,0,0,1,0,0,0,0,0],\n",
        "                      'A46': [0,0,0,0,0,0,1,0,0,0,0], 'A47': [0,0,0,0,0,0,0,1,0,0,0], 'A48': [0,0,0,0,0,0,0,0,1,0,0],\n",
        "                      'A49': [0,0,0,0,0,0,0,0,0,1,0], 'A410': [0,0,0,0,0,0,0,0,0,0,1]}\n",
        "            data.extend(attr_4[parts[3]])\n",
        "            # Attribute 5: (numerical) # Credit amount\n",
        "            data.append(numeric_transformer(parts[4]))\n",
        "            # Attibute 6: (qualitative) Savings account / bonds\n",
        "            attr_6 = {'A61': [1,0,0,0,0], 'A62': [0,1,0,0,0], 'A63': [0,0,1,0,0], 'A64': [0,0,0,1,0], 'A65': [0,0,0,0,1]}\n",
        "            data.extend(attr_6[parts[5]])\n",
        "            # Attribute 7: (qualitative) Present employment since\n",
        "            attr_7 = {'A71': [1,0,0,0,0], 'A72': [0,1,0,0,0], 'A73': [0,0,1,0,0], 'A74': [0,0,0,1,0], 'A75': [0,0,0,0,1]}\n",
        "            data.extend(attr_7[parts[6]])\n",
        "            # Attribute 8: (numerical) Installment rate in percentage of disposable income\n",
        "            data.append(numeric_transformer(parts[7]))\n",
        "            # Attribute 9: (qualitative) Personal status and sex\n",
        "            attr_9 = {'A91': [1,0,0,0,0], 'A92': [0,1,0,0,0], 'A93': [0,0,1,0,0], 'A94': [0,0,0,1,0], 'A95': [0,0,0,0,1]}\n",
        "            data.extend(attr_9[parts[8]])\n",
        "            # Attribute 10: (qualitative) Other debtors / guarantors\n",
        "            attr_10 = {'A101': [1,0,0], 'A102': [0,1,0], 'A103': [0,0,1]}\n",
        "            data.extend(attr_10[parts[9]])\n",
        "            # Attribute 11: (numerical) Present residence since\n",
        "            data.append(numeric_transformer(parts[10]))\n",
        "            # Attribute 12: (qualitative) Property\n",
        "            attr_12 = {'A121': [1,0,0,0], 'A122': [0,1,0,0], 'A123': [0,0,1,0], 'A124': [0,0,0,1]}\n",
        "            data.extend(attr_12[parts[11]])\n",
        "            # Attribute 13: (numerical) Age in years\n",
        "            data.append(numeric_transformer(parts[12]))\n",
        "            # Attribute 14: (qualitative) Other installment plans\n",
        "            attr_14 = {'A141': [1,0,0], 'A142': [0,1,0], 'A143': [0,0,1]}\n",
        "            data.extend(attr_14[parts[13]])\n",
        "            # Attribute 15: (qualitative) Housing\n",
        "            attr_15 = {'A151': [1,0,0], 'A152': [0,1,0], 'A153': [0,0,1]}\n",
        "            data.extend(attr_15[parts[14]])\n",
        "            # Attribute 16: (numerical) Number of existing credits at this bank\n",
        "            data.append(numeric_transformer(parts[15]))\n",
        "            # Attribute 17: (qualitative) Job\n",
        "            attr_17 = {'A171': [1,0,0,0], 'A172': [0,1,0,0], 'A173': [0,0,1,0], 'A174': [0,0,0,1]}\n",
        "            data.extend(attr_17[parts[16]])\n",
        "            # Attribute 18: (numerical) Number of people being liable to provide maintenance for\n",
        "            data.append(numeric_transformer(parts[17]))\n",
        "            # Attribute 19: (qualitative) # Telephone\n",
        "            attr_19 = {'A191': [1,0], 'A192': [0,1]}\n",
        "            data.extend(attr_19[parts[18]])\n",
        "            # Attribute 20: (qualitative) foreign worker\n",
        "            attr_20 = {'A201': [1,0], 'A202': [0,1]}\n",
        "            data.extend(attr_20[parts[19]])\n",
        "            dataset.append(data)\n",
        "            # 1 good, 2 bad for credit application\n",
        "            labels.append(1 if parts[20] == \"1\" else 0)\n",
        "        file.close()\n",
        "        return np.array(dataset, dtype=np.float32), np.array(labels, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import sklearn.ensemble as skle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def confidence_interval(x, N):\n",
        "\n",
        "   lower = np.mean(x) - ((1.96) * ( np.std(x) / np.sqrt(N) ))\n",
        "   upper = np.mean(x) + ((1.96) * ( np.std(x) / np.sqrt(N) ))\n",
        "\n",
        "   return lower, upper\n",
        "\n",
        "\n",
        "knn_parameter_grid = {\"kneighborsclassifier__metric\": [\"cosine\", \"euclidean\", \"manhattan\"],\n",
        "                          \"kneighborsclassifier__n_neighbors\": [2, 3, 4]\n",
        "                          }\n",
        "\n",
        "svm_parameter_grid = {\"svc__C\": [0.1, 0.5],\n",
        "              \"svc__kernel\": [\"poly\", \"rbf\"]\n",
        "}\n",
        "\n",
        "\n",
        "decision_tree_parameter_grid = {\"decisiontreeclassifier__criterion\" : [\"gini\", \"entropy\"],\n",
        "                                  \"decisiontreeclassifier__splitter\" : [\"best\", \"random\"]\n",
        "                                }\n",
        "\n",
        "random_forest_parameter_grid = { \"criterion\" : [\"gini\", \"entropy\"],\n",
        "                                \"n_estimators\" : [10,100]\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        "#please change datapath to wherever credit.data is stored in ur pc\n",
        "data_path = \"credit.data\"\n",
        "dataset, labels = DataLoader.load_credit_with_onehot(data_path)\n",
        "\n",
        "\n",
        "outer_cross_validation = RepeatedStratifiedKFold(n_splits=3, n_repeats=5, random_state=np.random.randint(1, 1000))\n",
        "inner_cross_validation = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=np.random.randint(1, 1000))\n",
        "\n",
        "knn_performance = []\n",
        "svm_performance = []\n",
        "decision_tree_performance =[]\n",
        "\n",
        "\n",
        "knn_overall_performance = []\n",
        "svm_overall_performance = []\n",
        "decision_tree_overall_performance =[]\n",
        "rf_overall_performance =[]\n",
        "\n",
        "\n",
        "best_inner = {}\n",
        "best_inner_svm = {}\n",
        "best_inner_decision_tree = {}\n",
        "\n",
        "all_combs =[]\n",
        "all_comb_svm =[]\n",
        "all_combs_decision_tree = []\n",
        "\n",
        "i=0\n",
        "\n",
        "for train_indices, test_indices in outer_cross_validation.split(dataset, labels):\n",
        "\n",
        "\n",
        "    current_training_part = dataset[train_indices]\n",
        "    current_training_part_label = labels[train_indices]\n",
        "\n",
        "\n",
        "    print(\"---------------------------------------------------\")\n",
        "    print(\"Inner iteration number: %d \\n\" %(i+1))\n",
        "\n",
        "\n",
        "\n",
        "    knn_pipeline = make_pipeline(MinMaxScaler(), KNeighborsClassifier())\n",
        "    knn_grid_search = GridSearchCV(knn_pipeline, param_grid=knn_parameter_grid, refit=True, cv=inner_cross_validation, scoring=\"f1_micro\")\n",
        "    knn_grid_search.fit(current_training_part, current_training_part_label)\n",
        "\n",
        "\n",
        "\n",
        "    best_inner[i] = knn_grid_search.best_params_\n",
        "    all_comb = knn_grid_search.cv_results_['params']\n",
        "    #current_best_hyperparamater's index in the params dictionary\n",
        "    index = [k for k, val in enumerate( np.array(best_inner[i]) == np.array(all_comb)  ) if val]\n",
        "    index= index[0]\n",
        "    #print(index)\n",
        "\n",
        "    #need this array to calculate it's confidence interval\n",
        "    array_of_all_scores_of_current_best = [ knn_grid_search.cv_results_['split{i}_test_score'.format(i = k) ][index]  for k in range(25)]\n",
        "\n",
        "    print(\"The current best hyperparameter for KNN in the inner CV: \")\n",
        "    print(all_comb[index])\n",
        "    print(\"Mean test score of this hyperparamter      : %f\" %(knn_grid_search.cv_results_['mean_test_score'][index]))\n",
        "    print( \" With the confidence interval: [  %f   %f ] \\n\"  %(confidence_interval(array_of_all_scores_of_current_best, len(array_of_all_scores_of_current_best))))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    svm_pipeline = make_pipeline(MinMaxScaler(), SVC())\n",
        "    svm_grid_search = GridSearchCV(svm_pipeline, param_grid=svm_parameter_grid, refit=True, cv=inner_cross_validation, scoring=\"f1_micro\")\n",
        "    svm_grid_search.fit(current_training_part, current_training_part_label)\n",
        "\n",
        "\n",
        "    best_inner_svm[i] = svm_grid_search.best_params_\n",
        "\n",
        "    all_comb_svm = svm_grid_search.cv_results_['params']\n",
        "\n",
        "    #current_best_hyperparamater's index in the params dictionary\n",
        "    index_svm = [k for k, val in enumerate( np.array(best_inner_svm[i]) == np.array(all_comb_svm)  ) if val]\n",
        "    index_svm= index_svm[0]\n",
        "    #print(index)\n",
        "\n",
        "    #need this array to calculate it's confidence interval\n",
        "    array_of_all_scores_of_current_best_svm = [ svm_grid_search.cv_results_['split{i}_test_score'.format(i = k) ][index_svm]  for k in range(25) ]\n",
        "\n",
        "    print(\"The current best hyperparameter for SVM in the inner CV: \")\n",
        "    print(all_comb_svm[index_svm])\n",
        "    print(\"Mean test score of this hyperparamter : %f\" %(svm_grid_search.cv_results_['mean_test_score'][index_svm]))\n",
        "    print( \" With the confidence interval: [  %f   %f ] \\n\"  %(confidence_interval(array_of_all_scores_of_current_best_svm, len(array_of_all_scores_of_current_best_svm))))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    decision_tree_pipeline  = make_pipeline(MinMaxScaler(), DecisionTreeClassifier())\n",
        "    decision_tree_grid_search = GridSearchCV(decision_tree_pipeline, param_grid=decision_tree_parameter_grid, refit=True, cv=inner_cross_validation, scoring=\"f1_micro\")\n",
        "    decision_tree_grid_search.fit(current_training_part, current_training_part_label)\n",
        "\n",
        "\n",
        "    best_inner_decision_tree[i] = decision_tree_grid_search.best_params_\n",
        "\n",
        "    all_comb_decision_tree = decision_tree_grid_search.cv_results_['params']\n",
        "\n",
        "    #current_best_hyperparamater's index in the params dictionary\n",
        "    index_decision_tree = [k for k, val in enumerate( np.array(best_inner_decision_tree[i]) == np.array(all_comb_decision_tree)  ) if val]\n",
        "    index_decision_tree = index_decision_tree[0]\n",
        "\n",
        "\n",
        "    #need this array to calculate it's confidence interval\n",
        "    array_of_all_scores_of_current_best_decision_tree = [ decision_tree_grid_search.cv_results_['split{i}_test_score'.format(i = k) ][index_decision_tree]  for k in range(25) ]\n",
        "\n",
        "    print(\"The current best hyperparameter for decision tree in the inner CV: \")\n",
        "    print(all_comb_decision_tree[index_decision_tree])\n",
        "    print(\"Mean test score of this hyperparamter      : %f\" %(decision_tree_grid_search.cv_results_['mean_test_score'][index_decision_tree]))\n",
        "    print( \" With the confidence interval: [  %f   %f ] \\n\"  %(confidence_interval(array_of_all_scores_of_current_best_decision_tree, len(array_of_all_scores_of_current_best_decision_tree))))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Random forest grid search is done manually\n",
        "    current_test_part = dataset[test_indices]\n",
        "    current_test_part_label = labels[test_indices]\n",
        "\n",
        "    rf_performance = dict()\n",
        "\n",
        "    for inner_train_indices, inner_test_indices in inner_cross_validation.split(current_training_part, current_training_part_label):\n",
        "      for l in range(10):\n",
        "\n",
        "        inner_training_dataset = current_training_part[inner_train_indices]\n",
        "        inner_training_label = current_training_part_label[inner_train_indices]\n",
        "\n",
        "        inner_test_dataset = current_training_part[inner_test_indices]\n",
        "        inner_test_label = current_training_part_label[inner_test_indices]\n",
        "\n",
        "        inner_scaler = MinMaxScaler()\n",
        "        inner_scaler.fit(inner_training_dataset)\n",
        "        scaled_inner_training_dataset = inner_scaler.transform(inner_training_dataset)\n",
        "\n",
        "        scaled_inner_test_dataset = inner_scaler.transform(inner_test_dataset)\n",
        "\n",
        "        for criterion in random_forest_parameter_grid[\"criterion\"]:\n",
        "              for n_estimators in random_forest_parameter_grid[\"n_estimators\"]:\n",
        "\n",
        "                classifier = skle.RandomForestClassifier(criterion= criterion, n_estimators = n_estimators)\n",
        "                classifier.fit(scaled_inner_training_dataset, inner_training_label)\n",
        "\n",
        "                predicted = classifier.predict(scaled_inner_test_dataset)\n",
        "\n",
        "                if (l, criterion, n_estimators) not in rf_performance:\n",
        "                    rf_performance[(l, criterion, n_estimators)] = []\n",
        "                rf_performance[(l, criterion,  n_estimators)].append(f1_score(inner_test_label, predicted, average=\"micro\"))\n",
        "\n",
        "\n",
        "    best_parameter_RF = None\n",
        "    best_score_RF = -float('inf')\n",
        "\n",
        "    mean =[]\n",
        "    items_list =[]\n",
        "\n",
        "    for items in rf_performance:\n",
        "     items_list.append(items)\n",
        "     mean.append(np.mean(rf_performance[items]))\n",
        "\n",
        "\n",
        "    inner_winner = items_list[np.argmax(np.array(mean))]\n",
        "\n",
        "\n",
        "    print(\"The current best Random Forest hyperparameter inside inner CV:\")\n",
        "    print(inner_winner)\n",
        "    print(\"With mean score of %f\" %(np.max(np.array(mean))))\n",
        "    print(\"And confidence interval of [%f   %f]\"   %(confidence_interval(rf_performance[inner_winner], len(rf_performance[inner_winner]))))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    outer_scaler = MinMaxScaler()\n",
        "    outer_scaler.fit(current_training_part)\n",
        "\n",
        "\n",
        "    rf_with_best_param = skle.RandomForestClassifier(criterion = inner_winner[1], n_estimators = inner_winner[2] )\n",
        "    rf_with_best_param.fit(outer_scaler.transform(current_training_part), current_training_part_label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    i=i+1\n",
        "\n",
        "\n",
        "    knn_predicted = knn_grid_search.predict(current_test_part)\n",
        "    knn_overall_performance.append(f1_score(current_test_part_label, knn_predicted, average=\"micro\"))\n",
        "\n",
        "    svm_predicted = svm_grid_search.predict(current_test_part)\n",
        "    svm_overall_performance.append(f1_score(current_test_part_label, svm_predicted, average=\"micro\"))\n",
        "\n",
        "    decision_tree_predicted = decision_tree_grid_search.predict(current_test_part)\n",
        "    decision_tree_overall_performance.append(f1_score(current_test_part_label, decision_tree_predicted, average=\"micro\"))\n",
        "\n",
        "\n",
        "    rf_predicted = rf_with_best_param.predict(outer_scaler.transform(current_test_part))\n",
        "    rf_overall_performance.append(f1_score(current_test_part_label, rf_predicted, average=\"micro\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------\")\n",
        "print(\"Different algorithms performance on the outer test set  (WRT F1 score): \")\n",
        "print(\"KNN OVERALL PERFORMANCE: \")\n",
        "print(np.mean(knn_overall_performance))\n",
        "#print(knn_overall_performance)\n",
        "print(\"With the confidence interval: [  %f   %f ] \\n\" %(confidence_interval(knn_overall_performance, len(knn_overall_performance))))\n",
        "\n",
        "print(\"SVM OVERALL PERFORMANCE: \")\n",
        "print(np.mean(svm_overall_performance))\n",
        "print(\"With the confidence interval: [  %f   %f ] \\n\" %(confidence_interval(svm_overall_performance, len(svm_overall_performance))))\n",
        "\n",
        "\n",
        "print(\"DECISION TREE OVERALL PERFORMANCE: \")\n",
        "print(np.mean(decision_tree_overall_performance))\n",
        "print(\"With the confidence interval: [  %f   %f ] \\n\" %(confidence_interval(decision_tree_overall_performance, len(decision_tree_overall_performance))))\n",
        "\n",
        "\n",
        "\n",
        "print(\"RF OVERALL PERFORMANCE: \")\n",
        "print(np.mean(rf_overall_performance))\n",
        "print(\"With the confidence interval: [ %f  %f] \\n\" %(confidence_interval(rf_overall_performance, len(rf_overall_performance))))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7w3ETgGh2pA",
        "outputId": "f66d0cc0-81b5-4b9c-e8e5-66eb82722ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "Inner iteration number: 1 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'manhattan', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.723748\n",
            " With the confidence interval: [  0.711189   0.736307 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.763670\n",
            " With the confidence interval: [  0.751914   0.775425 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'random'}\n",
            "Mean test score of this hyperparamter      : 0.679241\n",
            " With the confidence interval: [  0.665878   0.692604 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(6, 'entropy', 100)\n",
            "With mean score of 0.772984\n",
            "And confidence interval of [0.762105   0.783863]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 2 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'euclidean', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.736732\n",
            " With the confidence interval: [  0.727445   0.746019 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.743923\n",
            " With the confidence interval: [  0.733985   0.753861 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.679165\n",
            " With the confidence interval: [  0.664357   0.693973 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(5, 'entropy', 100)\n",
            "With mean score of 0.756505\n",
            "And confidence interval of [0.745048   0.767963]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 3 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'cosine', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.695644\n",
            " With the confidence interval: [  0.684892   0.706395 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.742727\n",
            " With the confidence interval: [  0.733251   0.752203 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.656658\n",
            " With the confidence interval: [  0.643044   0.670272 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(5, 'entropy', 100)\n",
            "With mean score of 0.751747\n",
            "And confidence interval of [0.742574   0.760920]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 4 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'manhattan', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.720141\n",
            " With the confidence interval: [  0.708400   0.731883 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.765481\n",
            " With the confidence interval: [  0.754797   0.776165 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.686776\n",
            " With the confidence interval: [  0.673014   0.700538 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(0, 'entropy', 100)\n",
            "With mean score of 0.765176\n",
            "And confidence interval of [0.756034   0.774318]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 5 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'euclidean', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.712800\n",
            " With the confidence interval: [  0.701342   0.724257 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.750520\n",
            " With the confidence interval: [  0.739761   0.761278 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.681297\n",
            " With the confidence interval: [  0.666270   0.696324 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(2, 'entropy', 100)\n",
            "With mean score of 0.758332\n",
            "And confidence interval of [0.747524   0.769141]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 6 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'manhattan', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.697733\n",
            " With the confidence interval: [  0.688114   0.707352 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.735839\n",
            " With the confidence interval: [  0.724490   0.747188 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.673440\n",
            " With the confidence interval: [  0.661757   0.685122 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(6, 'entropy', 100)\n",
            "With mean score of 0.749027\n",
            "And confidence interval of [0.738528   0.759526]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 7 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'manhattan', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.691900\n",
            " With the confidence interval: [  0.681652   0.702148 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.730937\n",
            " With the confidence interval: [  0.721338   0.740536 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.680489\n",
            " With the confidence interval: [  0.663171   0.697807 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(0, 'entropy', 100)\n",
            "With mean score of 0.752587\n",
            "And confidence interval of [0.739595   0.765578]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 8 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'manhattan', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.716057\n",
            " With the confidence interval: [  0.707453   0.724660 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.748430\n",
            " With the confidence interval: [  0.737917   0.758943 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.690856\n",
            " With the confidence interval: [  0.679338   0.702374 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(1, 'gini', 100)\n",
            "With mean score of 0.764612\n",
            "And confidence interval of [0.756843   0.772381]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 9 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'manhattan', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.719051\n",
            " With the confidence interval: [  0.706252   0.731850 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.751424\n",
            " With the confidence interval: [  0.739741   0.763107 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'random'}\n",
            "Mean test score of this hyperparamter      : 0.674611\n",
            " With the confidence interval: [  0.658897   0.690325 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(8, 'gini', 100)\n",
            "With mean score of 0.759179\n",
            "And confidence interval of [0.748803   0.769554]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 10 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'cosine', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.713213\n",
            " With the confidence interval: [  0.702809   0.723617 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.754344\n",
            " With the confidence interval: [  0.744760   0.763928 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'random'}\n",
            "Mean test score of this hyperparamter      : 0.681975\n",
            " With the confidence interval: [  0.664963   0.698987 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(4, 'entropy', 100)\n",
            "With mean score of 0.759477\n",
            "And confidence interval of [0.749899   0.769055]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 11 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'cosine', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.722646\n",
            " With the confidence interval: [  0.710924   0.734369 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.761367\n",
            " With the confidence interval: [  0.749515   0.773219 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.695372\n",
            " With the confidence interval: [  0.682762   0.707982 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(3, 'entropy', 100)\n",
            "With mean score of 0.773060\n",
            "And confidence interval of [0.761984   0.784136]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 12 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'cosine', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.688385\n",
            " With the confidence interval: [  0.675454   0.701316 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.738222\n",
            " With the confidence interval: [  0.726370   0.750075 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'random'}\n",
            "Mean test score of this hyperparamter      : 0.675832\n",
            " With the confidence interval: [  0.659795   0.691869 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(7, 'gini', 100)\n",
            "With mean score of 0.749000\n",
            "And confidence interval of [0.739969   0.758032]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 13 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'cosine', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.733015\n",
            " With the confidence interval: [  0.724162   0.741869 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.750475\n",
            " With the confidence interval: [  0.741197   0.759753 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.684965\n",
            " With the confidence interval: [  0.670950   0.698979 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(0, 'gini', 100)\n",
            "With mean score of 0.758891\n",
            "And confidence interval of [0.748395   0.769388]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 14 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'cosine', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.724709\n",
            " With the confidence interval: [  0.713611   0.735806 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.769743\n",
            " With the confidence interval: [  0.758593   0.780893 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.683638\n",
            " With the confidence interval: [  0.671932   0.695344 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(5, 'entropy', 100)\n",
            "With mean score of 0.771236\n",
            "And confidence interval of [0.761397   0.781074]\n",
            "---------------------------------------------------\n",
            "Inner iteration number: 15 \n",
            "\n",
            "The current best hyperparameter for KNN in the inner CV: \n",
            "{'kneighborsclassifier__metric': 'euclidean', 'kneighborsclassifier__n_neighbors': 3}\n",
            "Mean test score of this hyperparamter      : 0.691184\n",
            " With the confidence interval: [  0.679201   0.703167 ] \n",
            "\n",
            "The current best hyperparameter for SVM in the inner CV: \n",
            "{'svc__C': 0.5, 'svc__kernel': 'poly'}\n",
            "Mean test score of this hyperparamter : 0.748136\n",
            " With the confidence interval: [  0.741289   0.754983 ] \n",
            "\n",
            "The current best hyperparameter for decision tree in the inner CV: \n",
            "{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
            "Mean test score of this hyperparamter      : 0.680013\n",
            " With the confidence interval: [  0.664012   0.696015 ] \n",
            "\n",
            "The current best Random Forest hyperparameter inside inner CV:\n",
            "(1, 'gini', 100)\n",
            "With mean score of 0.762520\n",
            "And confidence interval of [0.754991   0.770050]\n",
            "----------------------------------------------------------------------------------------------\n",
            "Different algorithms performance on the outer test set  (WRT F1 score): \n",
            "KNN OVERALL PERFORMANCE: \n",
            "0.7198018377659096\n",
            "With the confidence interval: [  0.711694   0.727909 ] \n",
            "\n",
            "SVM OVERALL PERFORMANCE: \n",
            "0.7557983132833432\n",
            "With the confidence interval: [  0.747837   0.763760 ] \n",
            "\n",
            "DECISION TREE OVERALL PERFORMANCE: \n",
            "0.6761917606228985\n",
            "With the confidence interval: [  0.664338   0.688046 ] \n",
            "\n",
            "RF OVERALL PERFORMANCE: \n",
            "0.759592526658395\n",
            "With the confidence interval: [ 0.751429  0.767756] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qcVx0DJkwOiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dqvlu_xYlrN5"
      }
    }
  ]
}